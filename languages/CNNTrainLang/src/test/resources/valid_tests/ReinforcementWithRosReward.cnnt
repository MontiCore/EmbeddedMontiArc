/* (c) https://github.com/MontiCore/monticore */
configuration ReinforcementWithRosReward {
    learning_method : reinforcement

    agent_name : "reinforcement-agent"

    environment : ros_interface {
        state_topic : "state"
        action_topic : "action"
        reset_topic : "reset"
        terminal_state_topic : "is_terminal"
        reward_topic: "reward"
    }

    context : cpu

    num_episodes : 300
    num_max_steps : 9999
    discount_factor : 0.998
    target_score : 1000
    training_interval : 10

    loss : huber

    use_fix_target_network : true
    target_network_update_interval : 100

    use_double_dqn : true

    replay_memory : buffer{
        memory_size : 1000000
        sample_size : 64
    }

    strategy : epsgreedy{
        epsilon : 1.0
        min_epsilon : 0.01
        epsilon_decay_method: linear
        epsilon_decay : 0.0001
    }

    optimizer : rmsprop{
        learning_rate : 0.001
        learning_rate_minimum : 0.00001
        weight_decay : 0.01
        learning_rate_decay : 0.9
        learning_rate_policy : step
        step_size : 1000
        rescale_grad : 1.1
        clip_gradient : 10
        gamma1 : 0.9
        gamma2 : 0.9
        epsilon : 0.000001
        centered : true
        clip_weights : 10
    }
}
