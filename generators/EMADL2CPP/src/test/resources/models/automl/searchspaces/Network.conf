configuration Network {
    num_epoch: (8:1:100)
    batch_size: (10:128)
    optimizer: adam {
        learning_rate: (0.001:0.0001:0.01)
        step_size: (100:10:1000)
        weight_decay: (0.0:0.01:0.9)
    }
}