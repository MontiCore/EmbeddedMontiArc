/* (c) https://github.com/MontiCore/monticore */
configuration MountaincarActor {

    strategy: ornstein_uhlenbeck {
        epsilon: 1.0
        min_epsilon: 0.01
        epsilon_decay_method: linear
        epsilon_decay: 0.01
        mu: (0.0)
        theta: (0.15)
        sigma: (0.3)
    }

    context: cpu
    learning_method: reinforcement
    rl_algorithm: ddpg
    critic: ddpg2.agent.mountaincarCritic

    environment: gym {
        name: "MountainCarContinuous-v0"
    }

    num_episodes: 200
    discount_factor: 0.999
    num_max_steps: 1000
    training_interval: 1
    snapshot_interval: 20

    replay_memory: buffer {
        memory_size: 1000000
        sample_size: 64
    }

    actor_optimizer: adam {
        learning_rate: 0.0001
    }

    critic_optimizer: adam {
        learning_rate: 0.001
    }
}