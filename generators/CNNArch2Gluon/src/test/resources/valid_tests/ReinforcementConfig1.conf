/* (c) https://github.com/MontiCore/monticore */

configuration ReinforcementConfig1 {

    learning_method: reinforcement

    environment: ros_interface {
        state_topic: "/environment/state"
        action_topic: "/environment/action"
        reset_topic: "/environment/reset"
    }

    agent_name: "reinforcement_agent"

    reward_function: reward.rewardFunction

    num_episodes: 1000
    target_score: 35000
    discount_factor: 0.99999
    num_max_steps: 10000
    training_interval: 1

    use_fix_target_network: true
    target_network_update_interval: 500

    snapshot_interval: 500

    use_double_dqn: true

    loss: huber

    replay_memory: buffer {
        memory_size: 1000000
        sample_size: 64
    }

    strategy: epsgreedy {
        epsilon: 1.0
        min_epsilon: 0.02
        epsilon_decay_method: linear
        epsilon_decay: 0.0001
    }

    optimizer: adam{
        learning_rate: 0.001
    }
}