/* (c) https://github.com/MontiCore/monticore */
configuration AtariQNet {
    agent_name: "AtariAgent"
    
    context: gpu

    learning_method: reinforcement
    rl_algorithm: dqn-algorithm

    environment: ros_interface { 
        state_topic: "/preprocessor/state"
        terminal_state_topic: "/preprocessor/terminal"
        reward_topic: "/preprocessor/reward"
        action_topic: "/gym/step"
        reset_topic: "/gym/reset"
    }

    discount_factor: 0.99

    num_episodes: 5000
    start_training_at: 0
    
    num_max_steps: 99999
    training_interval: 1

    use_fix_target_network: true
    target_network_update_interval: 10000
    use_double_dqn: false

    snapshot_interval: 500
    evaluation_samples: 100

    loss: huber
    
    replay_memory: buffer{
        memory_size : 50000
        sample_size : 32
    }

    strategy : epsgreedy{
        epsilon : 1.0
        min_epsilon : 0.05
        epsilon_decay_method: linear
        epsilon_decay_start: 15
        epsilon_decay : 0.002
    }

    optimizer : rmsprop {
        learning_rate : 0.00025
    }
}
